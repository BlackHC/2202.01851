{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "judicial-removal",
   "metadata": {},
   "source": [
    "# Extract Predictions from ImageNet using various `timm` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import blackhc.project.script"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "controlling-beginning",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "pacific-budapest",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/blackhc/PycharmProjects/gde_repro/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "distinct-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data.transforms_factory import transforms_imagenet_eval\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "neutral-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.data import create_dataset, create_loader, resolve_data_config\n",
    "from timm.data.transforms_factory import create_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "balanced-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alleged-inventory",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "graduate-credits",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth\" to /home/blackhc/.cache/torch/hub/checkpoints/resnet152d_ra2-5cac0439.pth\n"
     ]
    }
   ],
   "source": [
    "#model = timm.create_model(\"beit_large_patch16_224\", pretrained=True, scriptable=True)\n",
    "#model = timm.create_model(\"deit3_large_patch16_224_in21ft1k\", pretrained=True, scriptable=True)\n",
    "#model = timm.create_model(\"vit_base_patch16_384\", pretrained=True, scriptable=True)\n",
    "#model = timm.create_model(\"convnext_large_in22ft1k\", pretrained=True, scriptable=True)\n",
    "model = timm.create_model(\"resnet152d\", pretrained=True, scriptable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "artistic-bunny",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "appreciated-requirement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'url': 'https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/resnet152d_ra2-5cac0439.pth',\n",
       " 'num_classes': 1000,\n",
       " 'input_size': (3, 256, 256),\n",
       " 'pool_size': (8, 8),\n",
       " 'crop_pct': 1.0,\n",
       " 'interpolation': 'bicubic',\n",
       " 'mean': (0.485, 0.456, 0.406),\n",
       " 'std': (0.229, 0.224, 0.225),\n",
       " 'first_conv': 'conv1.0',\n",
       " 'classifier': 'fc',\n",
       " 'test_input_size': (3, 320, 320),\n",
       " 'architecture': 'resnet152d'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.pretrained_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "confirmed-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = resolve_data_config(dict(crop_pct=0.0), model=model)\n",
    "eval_transform = create_transform(**data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "yellow-tribe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from timm.models import apply_test_time_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "linear-method",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_time_pool = True\n",
    "if test_time_pool:\n",
    "    model, test_time_pool = apply_test_time_pool(model, data_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "handmade-ground",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monkey patch timm's forward_features\n",
    "model.__class__.forward_head = torch.jit.export(model.__class__.forward_head)\n",
    "model.__class__.forward_features = torch.jit.export(model.__class__.forward_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "demographic-gender",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.jit.optimized_execution(True)\n",
    "#jit_model = torch.jit.script(model)\n",
    "jit_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "incorporated-steering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "central-rhythm",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(\"imagenet\", os.path.expanduser(\"~/imagenet\"), \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "individual-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_pct = 1.0 if test_time_pool else data_config[\"crop_pct\"]\n",
    "loader = create_loader(\n",
    "    dataset,\n",
    "    input_size=data_config[\"input_size\"],\n",
    "    batch_size=96,\n",
    "    use_prefetcher=True,\n",
    "    interpolation=data_config[\"interpolation\"],\n",
    "    mean=data_config[\"mean\"],\n",
    "    std=data_config[\"std\"],\n",
    "    num_workers=8,\n",
    "    crop_pct=crop_pct,\n",
    "    pin_memory=True,\n",
    "    tf_preprocessing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "assigned-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ceramic-absolute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb50955a36d4bd991786eb9c66a5f6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels = []\n",
    "predictions = []\n",
    "with torch.inference_mode():\n",
    "    for batch_images, batch_labels in tqdm(loader):\n",
    "        batch_logits = jit_model(batch_images.cuda())\n",
    "        batch_probs = torch.nn.functional.softmax(batch_logits.cpu(), dim=-1)\n",
    "        labels += [batch_labels.cpu()]\n",
    "        predictions += [batch_probs]\n",
    "\n",
    "labels = torch.cat(labels)\n",
    "predictions = torch.cat(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sound-conservative",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_info = dict(predictions=predictions, labels=labels, pretrained_cfg=model.pretrained_cfg)\n",
    "\n",
    "torch.save(validation_info, f\"imagenet_val_probs_labels_{model.pretrained_cfg['architecture']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pressing-defensive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imagenet_val_features_labels_beit_large_patch16_224.pt\n",
      "imagenet_val_features_labels_convnext_large_in22ft1k.pt\n",
      "imagenet_val_features_labels_deit3_large_patch16_224_in21ft1k.pt\n",
      "imagenet_val_features_labels_vit_base_patch16_384.pt\n",
      "imagenet_val_probs_labels_beit_large_patch16_224.pt\n",
      "imagenet_val_probs_labels_convnext_large_in22ft1k.pt\n",
      "imagenet_val_probs_labels_deit3_large_patch16_224_in21ft1k.pt\n",
      "imagenet_val_probs_labels_resnet152d.pt\n",
      "imagenet_val_probs_labels_vit_base_patch16_384.pt\n"
     ]
    }
   ],
   "source": [
    "!ls *.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "worse-istanbul",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def gc_cuda():\n",
    "    \"\"\"Gargage collect Torch (CUDA) memory.\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "known-muslim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ce735f1648447bada94a2735bb9080",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/521 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def collect_features(jit_model, loader):\n",
    "    labels = []\n",
    "    features = []\n",
    "    with torch.inference_mode():\n",
    "        for batch_images, batch_labels in tqdm(loader):\n",
    "            #print(batch_images.shape)\n",
    "            batch_features = jit_model.forward_head(jit_model.forward_features(batch_images.cuda()), pre_logits=True)\n",
    "            #print(batch_features.shape)\n",
    "            labels += [batch_labels.cpu()]\n",
    "            features += [batch_features.cpu()]\n",
    "\n",
    "    gc_cuda()\n",
    "    #print(batch_features.shape)\n",
    "\n",
    "    labels = torch.cat(labels)\n",
    "    features = torch.cat(features)\n",
    "    return labels, features\n",
    "\n",
    "\n",
    "labels, features = collect_features(jit_model, loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "characteristic-infrastructure",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_features_info = dict(features=features, labels=labels, pretrained_cfg=model.pretrained_cfg)\n",
    "\n",
    "torch.save(validation_features_info, f\"imagenet_val_features_labels_{model.pretrained_cfg['architecture']}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ethical-mozambique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-trance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-welsh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parliamentary-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-bridges",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "european-bouquet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=tensor([0.5000, 0.5000, 0.5000]), std=tensor([0.5000, 0.5000, 0.5000]))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "cfg = model.pretrained_cfg\n",
    "eval_transform = transforms_imagenet_eval(\n",
    "    img_size=cfg[\"input_size\"][1],\n",
    "    crop_pct=1,\n",
    "    interpolation=cfg[\"interpolation\"],\n",
    "    mean=cfg[\"mean\"],\n",
    "    std=cfg[\"std\"],\n",
    "    use_prefetcher=False,\n",
    ")\n",
    "print(eval_transform)\n",
    "# data_config = resolve_data_config(dict(crop_pct=0.), model=model)\n",
    "# eval_transform=create_transform(**data_config)\n",
    "eval_transform.transforms = [\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Lambda(lambda img: img.convert(\"RGB\")),\n",
    "] + eval_transform.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "alleged-hello",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataloader = ds.pytorch(\n",
    "    batch_size=128,\n",
    "    transform=dict(images=eval_transform, labels=None),\n",
    "    tensors=[\"images\", \"labels\"],\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=8,\n",
    "    use_progress_bar=False,\n",
    "    use_local_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "olympic-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "sharing-constant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageNet\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /home/blackhc/imagenet\n",
       "    Split: val"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ImageNet(\"~/imagenet\", split=\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "marine-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Downloading scipy-1.9.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.9 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.9/43.9 MB\u001B[0m \u001B[31m26.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy<1.25.0,>=1.18.5 in /home/blackhc/anaconda3/envs/gde_repro/lib/python3.10/site-packages (from scipy) (1.23.1)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amateur-differential",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gde_repro]",
   "language": "python",
   "name": "conda-env-gde_repro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}